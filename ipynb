import keras #ケラスを使う宣言
import matplotlib.pyplot as plt #matplotlib描画用にmatplotを使う宣言
import numpy as np #数値計算ライブラリnumpyを使う宣言
import tensorflow as tf

from keras.datasets import mnist #データとしてmnistを使う宣言
from keras.models import Sequential #シーケンシャルモデルを使う宣言
from keras.layers import Dense,Dropout,Flatten #学習に使う層を読み込む宣言
from keras.layers import Conv2D,MaxPooling2D #学習に使う層を読み込む宣言
from keras.optimizers import SGD,RMSprop,adam,adadelta,adamax #最適化の手法を色々読み込む宣言
from keras import backend as K
# ファイル操作部品読み込み
from google.colab import files
from PIL import Image
# OpenCV読み込み
import cv2
# 修正パッチ読み込み
from google.colab.patches import cv2_imshow

#最終的な出力サイズ
num_classes = 10 

#並列実行のパラメータ
batch_size = 128 #1バッチ当たりの画像取り出し回数(データサンプル数/この数=パラメータ更新回数)
epochs = 12 #学習試行数


#mnistデータ読み込み
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
# backendがTensorFlowとTheanoで配列のshapeが異なるために2パターン記述
if K.image_data_format() == 'channels_first':
  # 1次元配列に変換
#train_images = train_images.reshape((60000, 28, 28,1))
#test_images = test_images.reshape((10000, 28, 28,1))
   train_images = train_images.reshape(train_images.shape[0], 1, img_rows, img_cols)
   test_images = test_images.reshape(test_images.shape[0], 1, img_rows, img_cols)
   input_shape = (1, img_rows, img_cols)
else:
  # 1次元配列に変換
   train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)
   test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)
   input_shape = (img_rows, img_cols, 1)


#正規化:色の濃さを0-255から0-1に変換　こうすると少し精度が上がるかも?
# 入力データの各画素値を0-1の範囲で正規化 学習コストを下げる!!
#train_images, test_images = train_images / 255, test_images / 255 #"各点の0-255の値を0-1に変換
train_images = train_images.astype('float32')
test_images = test_images.astype('float32')
train_images /= 255
test_images /= 255
print('train_images shape:', train_images.shape)
print(train_images.shape[0], 'train_images samples')
print(test_images.shape[0], 'test_images samples')
数字をその数字の確率の配列に変換
train_labels = keras.utils.to_categorical(train_labels, num_classes)
test_labels = keras.utils.to_categorical(test_labels, num_classes)
#学習モデル定義
model = Sequential()#モデルは単純連続結線モデル

# 入力層
model.add(Conv2D(32, (3, 3), 
                 activation='relu', 
                 #input_shape=input_shape))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
#出力層
model.add(Dense(10, activation='softmax')) #全結線での学習結果を０－９までの数字の確率に結び付ける

#学習モデルの概要表示
print('学習用サンプル数', train_images.shape[0])
print('テスト評価用サンプル数', test_images.shape[0])
model.summary()
#学習モデル実行
model.compile(
             optimizer=keras.optimizers.Adadelta(),
#              optimizer='SGD',
#             optimizer='RMSprop',
#              optimizer='adam',
#              optimizer='adamax',
#              loss='binary_crossentropy',
#           loss='categorical_crossentropy',
#              loss='mean_squared_error',
#             loss='squared_hinge',
#              metrics=['binary_accuracy'])
              loss=keras.losses.categorical_crossentropy,
                
              metrics=['accuracy'])#accuracyは通常はcategorical_accuracy

# モデルの学習
result = model.fit(train_images, train_labels,  # 学習する画像とラベルデータ
                    batch_size=batch_size,#1バッチ当たり画像数
                    epochs=epochs,     # 繰り返し学習回数
                    verbose=1,         # ログ出力
                    validation_data=(test_images, test_labels))#チェック用データ


#テストデータで学習結果評価

score = model.evaluate(test_images, test_labels, verbose=1)
print('損失値:', score[0])
print('精度:', score[1])

     # Setting Parameters
#acc = result.history['binary_accuracy']
acc = result.history['accuracy']
#val_acc = result.history['val_binary_accuracy']
val_acc = result.history['val_accuracy']
loss = result.history['loss']
val_loss = result.history['val_loss']

#学習のグラフにする
epochs = range(1, len(acc)　+ 1)

     #1) Accracy Plt
plt.plot(epochs, acc, color ="red" ,label = 'training acc')
plt.plot(epochs, val_acc, color ="blue" , label= 'validation acc')
plt.title('Training and Validation acc')
plt.legend()
plt.show()

        # 2) Loss Plt
plt.plot(epochs, loss, color ="royalblue" ,label = 'training loss')
plt.plot(epochs, val_loss, color ="hotpink" , label= 'validation loss')
plt.title('Training and Validation loss')
plt.legend()
plt.show()
%matplotlib inline
count = 0
show_max = 11
y = model.predict(train_images)
plt.ﬁgure(1, ﬁgsize=(12,8))
plt.subplots_adjust(wspace=0.5)
plt.gray()
for i in range(len(y)):
    if count > show_max:
        break 
    prediction = np.argmax(y[i, :])
    label = np.argmax(train_labels[i, :])
    if prediction != label:
      count = count+1
      plt.subplot(3, 4, count)
      x = train_images[i, :]
      x = x.reshape(28, 28)
      #plt.pcolor(255 - x)#正規化しない場合
      plt.pcolor(1 - x)#正規化した時はこっち
      plt.text(2, 26, label,color='blue', fontsize=48)
      plt.text(20, 26,prediction ,color='red', fontsize=48)
      plt.xlim(0, 27)
      plt.ylim(27, 0)
plt.show()
# ファイル操作部品読み込み
from google.colab import files
from PIL import Image
# OpenCV読み込み
import cv2

# 修正パッチ読み込み
from google.colab.patches import cv2_imshow



# 写真アップロード
for i in range(2):
  uploaded = files.upload()
  file_name = list(uploaded.keys())[0]

# 写真読み込み
  gray = cv2.imread("./" + file_name,cv2.IMREAD_GRAYSCALE)
  cv2_imshow(gray)
  gray_small = cv2.resize(gray , (28,28))
  cv2_imshow(gray_small)
  gray_inv = cv2.bitwise_not(gray_small)

  img = np.array(Image.fromarray(gray_inv))
  img = img.reshape((784))
  X = []
  X.append(img)
  X = np.asarray(X)
  #X = X.astype('float32')
  #X = X / 255.0

  result1 = model.predict(X)
  print('----------')

  print(result1.argmax())
  print('----------')
